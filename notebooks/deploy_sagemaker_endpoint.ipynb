{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "great-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend\n",
    "from sagemaker.tensorflow import TensorFlowModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-wonder",
   "metadata": {},
   "source": [
    "## Preparing model.tar.gz for deploying to Sagemaker Endpoint\n",
    "Pretrained YoloV5 models can be accessed through https://github.com/ultralytics/yolov5\n",
    "\n",
    "First, `git clone https://github.com/ultralytics/yolov5` to your `ROOT` directory, then within the `ROOT/yolov5` directory, you can retrieve a pretrained yolov5 model by running the following command: `python export.py --weights yolov5l.pt --include saved_model --nms`. This will create a directory called `yolov5l_saved_model`. \n",
    "\n",
    "In order to deploy this model onto SageMaker Endpoints, it must be packaged in the following structure:\n",
    "\n",
    "```\n",
    "export\n",
    "└──Servo\n",
    "   └──1\n",
    "      │  saved_model.pb\n",
    "      └──assets\n",
    "      └──variables\n",
    "         │ variables.data-00000-of-00001\n",
    "         │ variables.index\n",
    "```\n",
    "\n",
    "To get the correct data structure for `model.tar.gz`, copy the contents from `yolov5l_saved_model` into `export/Servo/1/`. Once you have the correct, directory structure for your model, use `tar -czvf model.tar.gz export` to get your `model.tar.gz`.\n",
    "\n",
    "Upload `model.tar.gz` to your s3 bucket of your choice, and make sure your ec2 instance or sagemaker instance has the correct IAM roles to access the s3 bucket where `model.tar.gz` will be located. \n",
    "\n",
    "In my case, my `model.tar.gz` will be uploaded to `s3://sagemaker-us-east-1-171547146718/model.tar.gz`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vocal-minimum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: _moduleraw: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `_moduleraw'\n",
      "export/\n",
      "export/Servo/\n",
      "export/Servo/1/\n",
      "export/Servo/1/.ipynb_checkpoints/\n",
      "export/Servo/1/variables/\n",
      "export/Servo/1/variables/variables.index\n",
      "export/Servo/1/variables/variables.data-00000-of-00001\n",
      "export/Servo/1/assets/\n",
      "export/Servo/1/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "!tar -czvf model.tar.gz export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hispanic-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = 's3://<s3 bucket>/model.tar.gz'\n",
    "role = '<IAM ROLE>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "consistent-dodge",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "model = TensorFlowModel(model_data=model_data, \n",
    "                        framework_version='2.3', role=role)\n",
    "predictor = model.deploy(initial_instance_count=1, \n",
    "                         instance_type='ml.m4.xlarge',\n",
    "                         #instance_type='ml.g4dn.xlarge',#'ml.m4.xlarge',\n",
    "                         #accelerator_type='ml.eia2.medium',\n",
    "                         endpoint_name='checkride-demo-yolov5l')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-belly",
   "metadata": {},
   "source": [
    "That's it! Now you're ready to invoke the sagemaker endpoint to get predictions back"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p38)",
   "language": "python",
   "name": "conda_tensorflow2_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
